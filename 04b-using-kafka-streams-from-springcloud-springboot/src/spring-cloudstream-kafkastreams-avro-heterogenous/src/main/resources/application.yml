spring:
  application:
    name: "spring-boot-kafkastreams"

  cloud:
    stream:
      bindings:
        process-in-0:
          consumer:
            valueSerde: io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde
            configuration:
              schema.registry.url: http://dataplatform:8081
              value:
                subject.name.strategy: io.confluent.kafka.serializers.subject.TopicRecordNameStrategy
          destination: test-kstream-spring-cloudstream-input-topic
        process-out-0:
          producer:
            valueSerde: io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde
            configuration:
              schema.registry.url: http://dataplatform:8081
              value:
                subject.name.strategy: io.confluent.kafka.serializers.subject.TopicRecordNameStrategy
          destination: test-kstream-spring-cloudstream-output-topic

      kafka:
        streams:
          binder:
            applicationId: spring-boot-springcloud-kafkastreams
            configuration:
              commit.interval.ms: 100
              cache.max.bytes.buffering: 0
#            default.key.serde: org.apache.kafka.common.serialization.Serdes$VoidSerde
#            default.value.serde: io.confluent.kafka.serializers.KafkaAvroSerializer
              schema.registry.url: http://dataplatform:8081
              specific.avro.reader: true
              value:
                subject.name.strategy: io.confluent.kafka.serializers.subject.TopicRecordNameStrategy

  kafka:
    bootstrap-servers: dataplatform:9092

logging:
  level:
    root: info
    com.trivadis.kafkws.springboot.springboot.cloudstream.kafkastreams: debug

management:
  endpoint:
    health.show-details: ALWAYS

  endpoints:
    web:
      exposure:
        include: metrics, kafkastreamstopology